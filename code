# -*- coding: utf-8 -*-
"""
期末專題：教育數據的問題定義與模型分析
主題：基於機器學習之學生學業表現預測與行為分析系統
資料來源：UCI Student Performance Dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# 設定中文字體 (若在 Colab 執行可能需要額外安裝字體，此處以標準繪圖為主)
plt.rcParams['font.sans-serif'] = ['Arial'] 
plt.rcParams['axes.unicode_minus'] = False

# ==========================================
# 1. 資料來源與取得方式 (要求 2)
# ==========================================
url = "https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/student-mat.csv"
df = pd.read_csv(url)

# ==========================================
# 2. 資料欄位說明與探索 (要求 4)
# ==========================================
# 選取關鍵欄位
cols = ['G3', 'G1', 'G2', 'absences', 'studytime', 'failures', 'Medu', 'Fedu', 'goout']
df_subset = df[cols]

# 繪製熱力圖 (Heatmap)
plt.figure(figsize=(10, 8))
sns.heatmap(df_subset.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Educational Data Feature Correlation Heatmap')
plt.show()

# ==========================================
# 3. 監督式學習：預測是否及格 (要求 5)
# ==========================================
# 問題定義：G3 >= 10 為及格 (1)，否則為不及格 (0)
df['target'] = (df['G3'] >= 10).astype(int)

X = df[['G1', 'G2', 'absences', 'studytime', 'failures', 'Medu', 'Fedu', 'goout']]
y = df['target']

# 分割資料集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 模型分析：隨機森林
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# 輸出結果 (截圖用)
print("--- 監督式學習：隨機森林分類報告 ---")
print(classification_report(y_test, y_pred))

# 繪製混淆矩陣
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix: Random Forest')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# 繪製特徵重要性
importances = rf.feature_importances_
feat_importances = pd.Series(importances, index=X.columns).sort_values()
plt.figure(figsize=(8, 6))
feat_importances.plot(kind='barh', color='skyblue')
plt.title('Feature Importances (Random Forest)')
plt.show()

# ==========================================
# 4. 非監督式學習：學生行為分群 (要求 6)
# ==========================================
# 選取行為維度 (缺席) 與 成就維度 (成績)
X_cluster = df[['absences', 'G3']]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_cluster)

# 肘部法 (Elbow Method)
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

# K-means 分群 (k=3)
kmeans = KMeans(n_clusters=3, random_state=42)
df['Cluster'] = kmeans.fit_predict(X_scaled)

# 繪製分群散佈圖
plt.figure(figsize=(10, 7))
sns.scatterplot(data=df, x='absences', y='G3', hue='Cluster', palette='viridis', s=100)
plt.title('K-means Clustering: Student Behavior vs Achievement')
plt.show()

print("--- 程式執行完成 ---")
